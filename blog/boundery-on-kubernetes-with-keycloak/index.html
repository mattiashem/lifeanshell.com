<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
    <link rel="icon" href="img/favicon.ico" type="image/png">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Spent most of my days with a shell, deploys apps, writing code ore fixing problems with automating, This is some of the stuff a work on right now " />
        <meta name="keywords" content="kubernernetes samma.io sre linux docker devops ks8 help blog fix problems" />
        <meta property="og:title" content="Lifeandshell - Mattias Hemmingsson" />
        <meta property="og:type" content="devsecops devops sre drones hacking" />
        <meta property="og:url" content="https://lifeadnshell.com" />
        <meta property="og:description" content="Lifeandshell - Mattias Hemmingsson - SRE Devops - And more " />

    <title>Mattias Hemmingsson {'rendered': 'Boundery on Kubernetes with Keycloak'} </title>
    <!-- font icons -->
    <link rel="stylesheet" href="/assets/vendors/themify-icons/css/themify-icons.css">
    <!-- Bootstrap + Steller main styles -->
	<link rel="stylesheet" href="/assets/css/steller.css">
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="40" id="home">

    <!-- Page navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" data-spy="affix" data-offset-top="0">
        <div class="container">
            <a class="navbar-brand" href="#"><img src="/img/hrb.png" alt=""></a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav ml-auto align-items-center">
                    <li class="nav-item">
                        <a class="nav-link" href="/">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/blog">Blog</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/">Contact</a>
                    </li>
                </ul>
            </div>
        </div>          
    </nav>
    <!-- End of page navibation -->
    <!-- Blog Section -->
    <section id="blog" class="section">
        <div class="container text-center">
            <h6 class="subtitle"></h6>
            <p class="mb-5 pb-4"></p>

            <div class="row text-left">

    <h2>{'rendered': 'Boundery on Kubernetes with Keycloak'}</h2>
    <p>{'rendered': '\n<p>We have 3 clusters running 2 on AWS and 1 on-prem. And to sort out connections for developers and admin the goal is to implement boundary as an access point. To verify the user we use Keycloak and 2FA, Then based on roles we give the different users access to different services inside the cluster.<br><br>Service<br>The user should be able to connect to an ssh server inside the network but also to service running inside Kubernetes like elasticsearch ore MySQL,</p>\n\n\n\n<p class="has-medium-font-size">2 stages</p>\n\n\n\n<p>We are to set up boundary in two stages the first is to deploy the boundary service into the cluster. And the second is to config boundery using terraform.</p>\n\n\n\n<p class="has-medium-font-size">Requirement</p>\n\n\n\n<p>To get started we have a Kubernetes cluster and we also need an external that we can use to get access. I will expose the boundary service using metal-lb but you can change to use node ports on example EKS or GCP.</p>\n\n\n\n<p>Postgress SQL boundary uses a Postgres SQL to store its configs. We need a Postgres SQL with username and password ready.</p>\n\n\n\n<p></p>\n\n\n\n<p></p>\n\n\n\n<p>We also need some keys to be used for bounder and the easy way to generate new keys are to run boundary dev </p>\n\n\n\n<p><code>boundary dev</code></p>\n\n\n\n<p></p>\n\n\n\n<pre class="wp-block-code"><code>\n   &#91;Controller] AEAD Key Bytes: kj9LoQqyZs2a3cfwmDy/u3tDwWdGEyPYhY3rXDoc5+A=\n   &#91;Recovery] AEAD Key Bytes: 2kgQXuYYuc5TyTyNi+DOg+DqiJVqZFuWlohUPfhz1Tc=\n   &#91;Worker-Auth] AEAD Key Bytes: okXvaWDI2FuRZO6ZnNJm1vBXL32jZsnrMNuZ7wQ8MHE=</code></pre>\n\n\n\n<ol class="has-medium-font-size"><li>Lets deploy </li></ol>\n\n\n\n<p>Let&#8217;s get a certificate with lets encrypt</p>\n\n\n\n<p><code>apiVersion: cert-manager.io/v1<br>kind: Certificate<br>metadata:<br>name: boundery-tls<br>namespace: boundery<br>spec:<br>secretName: boundery-tls<br>issuerRef:<br>name: letsencrypt<br>kind: ClusterIssuer<br>commonName: boundery.example.com<br>dnsNames:<br>- boundery.example.com</code></p>\n\n\n\n<p>PSP</p>\n\n\n\n<p>I have a cluster that enforces PSP hard and for that, I use the following PSP. You may not need this for example on EKS and PSP is to be terminated.</p>\n\n\n\n<pre class="wp-block-code"><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: controller\n  namespace: boundery\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: runtime/default\n    seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default\n  name: 10-boundery-controller\nspec:\n  allowedCapabilities:\n    - IPC_LOCK\n    - SETFCAP\n  fsGroup:\n    rule: RunAsAny\n  privileged: true\n  runAsUser:\n    rule: RunAsAny\n  seLinux:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  volumes:\n  - secret\n  - configMap\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    kubernetes.io/cluster-service: "true"\n  name: psp-boundery-controller                    # named for psp-&lt;namespace&gt;-&lt;serviceaccount&gt;\nrules:\n- apiGroups:\n  - policy\n  resourceNames:\n  - 10-boundery-controller\n  resources:\n  - podsecuritypolicies\n  verbs:\n  - use\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  annotations:\n    kubernetes.io/description: \'tailored PSP for vault\'\n  labels:\n    kubernetes.io/cluster-service: "true"\n  name: psp-boundery-controller\n  namespace: boundery\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: psp-boundery-controller\nsubjects:\n  - kind: ServiceAccount\n    namespace: boundery\n    name: controller</code></pre>\n\n\n\n<p></p>\n\n\n\n<p>Now we can deploy the controller</p>\n\n\n\n<p>You need to add the keys from above and also add the posgress password IN 2 PLACES</p>\n\n\n\n<div class="wp-block-group"><div class="wp-block-group__inner-container is-layout-flow wp-block-group-is-layout-flow">\n<p></p>\n\n\n\n<pre class="wp-block-code"><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: boundery\nnamespace: boundery\ndata:\nboundary.hcl: |-\n    # Disable memory lock: https://www.man7.org/linux/man-pages/man2/mlock.2.html\n    disable_mlock = true    \n    # Controller configuration block\n    controller {\n      # This name attr must be unique across all controller instances if running in HA mode\n      name = "controller"\n      description = "Controller"\n      public_cluster_addr = "boundery.example.com"\n      # Database URL for postgres. This can be a direct "postgres://"\n      # URL, or it can be "file://" to read the contents of a file to\n      # supply the url, or "env://" to name an environment variable\n      # that contains the URL.\n       database {\n          url = "env://BOUNDARY_PG_URL"\n      }\n    }\n\n    # API listener configuration block\n    listener "tcp" {\n      # Should be the address of the NIC that the controller server will be reached on\n      address = "0.0.0.0"\n      # The purpose of this listener block\n      purpose = "api"\n\n      tls_disable = false\n      tls_cert_file = "/tls/tls.crt"\n      tls_key_file  = "/tls/tls.key"\n      tls_min_version = "tls13"\n\n\n\n\n      # Uncomment to enable CORS for the Admin UI. Be sure to set the allowed origin(s)\n      # to appropriate values.\n      cors_enabled = false\n      #cors_allowed_origins = &#91;"https://boundery.examples.com", "serve://boundary"]\n    }\n\n    # Data-plane listener configuration block (used for worker coordination)\n    listener "tcp" {\n      # Should be the IP of the NIC that the worker will connect on\n      address = "0.0.0.0"\n      # The purpose of this listener\n      purpose = "cluster"\n      tls_disable = false\n      tls_cert_file = "/tls/tls.crt"\n      tls_key_file  = "/tls/tls.key"\n      tls_min_version = "tls13"\n\n    }\n\n    # Root KMS configuration block: this is the root key for Boundary\n    # Use a production KMS such as AWS KMS in production installs\n    kms "aead" {\n      purpose = "root"\n      aead_type = "aes-gcm"\n      key = "ADD YOUR HERE"\n      key_id = "global_root"\n    }\n\n    # Worker authorization KMS\n    # Use a production KMS such as AWS KMS for production installs\n    # This key is the same key used in the worker configuration\n    kms "aead" {\n      purpose = "worker-auth"\n      aead_type = "aes-gcm"\n      key = "ADD YOUR HERE"\n      key_id = "global_worker-auth"\n    }\n\n    # Recovery KMS block: configures the recovery key for Boundary\n    # Use a production KMS such as AWS KMS for production installs\n    kms "aead" {\n      purpose = "recovery"\n      aead_type = "aes-gcm"\n      key = "ADD YOUR HERE"\n      key_id = "global_recovery"\n    }\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\nname: controller\nnamespace: boundery\nspec:\nreplicas: 1\nselector:\nmatchLabels:\napp: controller\nserviceName: controller\npodManagementPolicy: Parallel\ntemplate:\nmetadata:\nlabels:\napp: controller\nname: controller\nspec:\ninitContainers:\n- name: init-db\nimage: hashicorp/boundary:0.7.1\nargs: &#91;"database", "init","-skip-auth-method-creation","-skip-host-resources-creation","-skip-scopes-creation","-skip-target-creation","-config", "/boundary/boundary.hcl"]\nenv:\n- name: BOUNDARY_PG_URL\nvalue: postgresql://postgres:PASSWORD@boundery-postgresql:5432/boundery?sslmode=disable\n- name: HOSTNAME\nvalue: boundary\nsecurityContext:\ncapabilities:\nadd:\n- IPC_LOCK\nvolumeMounts:\n- name: config\nmountPath: /boundary/boundary.hcl\nsubPath: boundary.hcl\nreadOnly: true\n- name: tls\nmountPath: /tls\nreadOnly: true\n  containers:\n    - name: controller\n      image: hashicorp/boundary:0.7.1\n      args: &#91;"server", "-config", "/boundary/boundary.hcl"]\n      env:\n        - name: BOUNDARY_PG_URL\n          value: postgresql://postgres:PASSWORD@boundery-postgresql:5432/boundery?sslmode=disable\n        - name: HOSTNAME\n          value: boundary\n      resources:\n        requests:\n          cpu: 200m\n          memory: 1024Mi\n        limits:\n          cpu: 500m\n          memory: 2048Mi           \n      ports:\n        - containerPort: 9200\n          name: api\n        - containerPort: 9201\n          name: connections\n        - containerPort: 9202\n          name: access\n      securityContext:\n        capabilities:\n          add:\n           - IPC_LOCK\n      volumeMounts:\n        - name: config\n          mountPath: /boundary/boundary.hcl\n          subPath: boundary.hcl\n          readOnly: true\n        - name: tls\n          mountPath: /tls\n          readOnly: true\n\n  serviceAccountName: controller\n  volumes:\n  - name: config\n    configMap:\n      name: boundery\n  - name: tls\n    secret:\n      secretName: boundery-tls</code></pre>\n\n\n\n<pre class="wp-block-preformatted">Apply the yaml to the cluster and verify the controller starts up. When it running we can go on deploying the worker.\n\nAdding Worker\n</pre>\n\n\n\n<hr class="wp-block-separator"/>\n\n\n\n<pre class="wp-block-code"><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: boundery-worker\n  namespace: boundery\ndata:\n  boundary.hcl: |-\n        # Disable memory lock: https://www.man7.org/linux/man-pages/man2/mlock.2.html\n        disable_mlock = true\n\n        listener "tcp" {\n                purpose = "proxy"\n                address = "0.0.0.0"\n                tls_disable = false\n                tls_cert_file = "/tls/tls.crt"\n                tls_key_file  = "/tls/tls.key"\n                tls_min_version = "tls13"\n                }\n        worker {\n          # Name attr must be unique across workers\n          name = "worker"\n          description = "Worker in the  cluster"\n\n        # Workers must be able to reach controllers on :9201\n         controllers = &#91;\n                 "boundery.example.com"\n         ]\n        public_addr = "boundery.example.com"\n        tags {\n           type   = &#91;"onprem"]\n           }\n         }\n        # must be same key as used on controller config\n        kms "aead" {\n          purpose = "worker-auth"\n          aead_type = "aes-gcm"\n          key = ""\n          key_id = "global_worker-auth"\n        }\n\n         \n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: worker\n  namespace: boundery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: worker\n  serviceName: worker\n  podManagementPolicy: Parallel\n  template:\n    metadata:\n      labels:\n        app: worker\n      name: worker\n    spec:   \n      containers:\n        - name: worker \n          image: hashicorp/boundary:0.7.1\n          args: &#91;"server", "-config", "/boundary/boundary.hcl"]\n          env:\n            - name: HOSTNAME\n              value: boundary\n          volumeMounts:\n            - name: config\n              mountPath: /boundary/boundary.hcl\n              subPath: boundary.hcl\n              readOnly: true\n            - name: tls\n              mountPath: /tls\n              readOnly: true\n          resources:\n            requests:\n              cpu: 200m\n              memory: 1024Mi\n            limits:\n              cpu: 500m\n              memory: 2048Mi           \n          ports:\n            - containerPort: 9201\n              name: connections\n          securityContext:\n            capabilities:\n              add:\n               - IPC_LOCK\n          volumeMounts:\n            - name: config\n              mountPath: /boundary/boundary.hcl\n              subPath: boundary.hcl\n              readOnly: true\n      serviceAccountName: worker\n      volumes:\n      - name: config\n        configMap:\n          name: boundery-worker\n      - name: tls\n        secret:\n          secretName: boundery-tls</code></pre>\n\n\n\n<p>Note the Following <br></p>\n</div></div>\n\n\n\n<pre class="wp-block-code"><code>        tags {\n           type   = &#91;"onprem"]\n           }\n         }</code></pre>\n\n\n\n<p>This is how we can make different works handle different endpoints. Say we have an ssh server that is only are accessible from the on-prem cluster. Then we need to tag the worker with on-prem. And also tag the connection we will create later with on-prem. Then we can control so the right worker handle the right endpoints</p>\n\n\n\n<p></p>\n\n\n\n<p></p>\n\n\n\n<p>Now let&#8217;s deploy our service so we can access the boundary server. Here I use metal-lb and external-dns to setup IP and DNS. You need to config this to match your setup.</p>\n\n\n\n<pre class="wp-block-code"><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: controller\n  namespace: boundery \n  annotations:\n    metallb.universe.tf/address-pool: boundery\n    metallb.universe.tf/allow-shared-ip: "boundery"\n    external-dns.alpha.kubernetes.io/hostname: boundery.example.com\nspec:\n  ports:\n  - port: 9200\n    name: controller\n    targetPort: 9200\n  - port: 9201\n    name: workers\n    targetPort: 9201\n  selector:\n    app: controller\n  type: LoadBalancer\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: worker\n  namespace: boundery\n  annotations:\n    metallb.universe.tf/address-pool: boundery\n    metallb.universe.tf/allow-shared-ip: "boundery"\nspec:\n  ports:\n  - port: 9202\n    name: api\n    targetPort: 9202\n  selector:\n    app: worker\n  type: LoadBalancer</code></pre>\n\n\n\n<p>Test now so you have access to boundary on port 9200 you should see the login page of boundery.<br>If not go back and check your settings, TLS certs are created and postgress is running.</p>\n\n\n\n<p></p>\n\n\n\n<p>If you have the login let&#8217;s move on to set up boundary with terraform </p>\n\n\n\n<p>First, we create the settings for boundary</p>\n\n\n\n<p>terraform.tf</p>\n\n\n\n<pre class="wp-block-code"><code>provider "boundary" {\n  addr             = "https://boundery.example.com:9200"\n  recovery_kms_hcl = &lt;&lt;EOT\nkms "aead" {\n    purpose   = "recovery"\n    aead_type = "aes-gcm"\n    key       = "ADD YOUR HERE"\n    key_id    = "global_recovery"\n}\nEOT\n}\n</code></pre>\n\n\n\n<p>This will then be used to connect to boundary and config it </p>\n\n\n\n<p>some scopes</p>\n\n\n\n<pre class="wp-block-code"><code>resource "boundary_scope" "bundery" {\n\n  scope_id    = "global"\n  name        = "Boundey"\n  description = "globa Tech"\n\n  auto_create_admin_role   = false\n  auto_create_default_role = true\n}\n\nresource "boundary_scope" "onprem" {\n  name                     = "Onprem"\n  description              = "Onprem"\n  scope_id                 = boundary_scope.bundery.id\n  auto_create_admin_role   = false\n  auto_create_default_role = true\n}\n\nresource "boundary_scope" "aws" {\n  name                     = "aws"\n  description              = "AWS Prod"\n  scope_id                 = boundary_scope.bundery.id\n  auto_create_admin_role   = false\n  auto_create_default_role = true\n}</code></pre>\n\n\n\n<p>Setting up auth against keycloak </p>\n\n\n\n<pre class="wp-block-code"><code>resource "boundary_auth_method_oidc" "keycloak" {\n  name        = "SSO"\n  description = "Keycloak SSO"\n  type        = "oidc"\n  api_url_prefix = "https://boundery.example.com:9200/"\n  client_id = "boundery"\n  is_primary_for_scope =  "true"\n  #claims_scopes = &#91;"aud","sub","iss","auth_time","name","given_name","family_name","preferred_username","email","acr"]\n  client_secret = "92e9509d-8215-4e53-8ffc-4f742fbab720"\n  scope_id    = "global"\n  signing_algorithms = &#91;"PS384","ES384","RS384","ES256","RS256","ES512","PS256","PS512","RS512"]\n  issuer = "https://auth.example.com/auth/realms/master"\n}\n</code></pre>\n\n\n\n<p>some auth </p>\n\n\n\n<pre class="wp-block-code"><code>\n#Logged in users\nresource "boundary_role" "user" {\n  name          = "user_org"\n  description   = "User"\n  principal_ids = &#91;"u_auth"]\n  grant_strings = &#91;\n        "id=*;type=*;actions=read,list",\n]\n  scope_id      = boundary_scope.boundery.id\n}\n\nresource "boundary_role" "user_onprem" {\n  name          = "access_onprem"\n  description   = "Access for onprem"\n  principal_ids = &#91;"u_auth"]\n  grant_strings = &#91;\n\t"id=*;type=*;actions=read,list,authorize-session",\n        "id=*;type=host-catalog;actions=read,list",\n        "id=*;type=target;actions=list,read,authorize-session",\n        "id=*;type=session;actions=cancel:self"\n\n]\n  scope_id      = boundary_scope.onprem.id\n}\nresource "boundary_role" "user_aws" {\n  name          = "access_aws"\n  description   = "Access for AWS"\n  principal_ids = &#91;"u_auth"]\n  grant_strings = &#91;\n        "id=*;type=*;actions=read,list,authorize-session",\n        "id=*;type=host-catalog;actions=read,list",\n        "id=*;type=target;actions=list,read,authorize-session",\n        "id=*;type=session;actions=cancel:self"\n]\n  scope_id      = boundary_scope.aws.id\n}\n\n\n\n## Anon Users\n\nresource "boundary_role" "global_anon_listing" {\n  scope_id = "global"\n  grant_strings = &#91;\n    "id=*;type=auth-method;actions=list,authenticate",\n    "id=*;type=scope;actions=read,list",\n    "id={{account.id}};actions=read,change-password"\n  ]\n  principal_ids = &#91;"u_anon"]\n}\n\n\n\n\nresource "boundary_role" "org_anon_listing_aws" {\n  scope_id = boundary_scope.aws.id\n  grant_strings = &#91;\n    "id=*;type=auth-method;actions=list,authenticate",\n    "id=*;type=scope;actions=read,list",\n    "id={{account.id}};actions=read,change-password"\n  ]\n  principal_ids = &#91;"u_anon"]\n}\n\n\n\nresource "boundary_role" "org_anon_listing_onprem" {\n  scope_id = boundary_scope.onprem.id\n  grant_strings = &#91;\n    "id=*;type=auth-method;actions=list,authenticate",\n    "id=*;type=scope;actions=read,list",\n    "id={{account.id}};actions=read,change-password"\n  ]\n  principal_ids = &#91;"u_anon"]\n}\n\n</code></pre>\n\n\n\n<p>And now finally let&#8217;s create some targets to connect to </p>\n\n\n\n<p></p>\n\n\n\n<pre class="wp-block-code"><code>\n#Make a hostgroup\nresource "boundary_host_catalog" "k8s_access" {\n  name        = "k8s"\n  description = "K8s Endpoints"\n  type        = "static"\n  scope_id    = boundary_scope.onprem.id\n}\n\n#Make a host\nresource "boundary_host" "search_onprem" {\n    type            = "static"\n    name            = "search"\n    description     = "search"\n    address         = "search.elasticsearch.svc" &lt;--- LOK AT THIS THIS WORKER IS RUNNING INSIDE K8S AND WE CAN ACCESS INTERNAL SERVICE !!!!\n    host_catalog_id = boundary_host_catalog.k8s_access.id\n  }\n\n\n# Make a Hostset \nresource "boundary_host_set" "search_onprem" {\n  type            = "static"\n  name            = "k8s_master"\n  description     = "Host set for k8s master"\n  host_catalog_id = boundary_host_catalog.k8s_access.id\n  host_ids        = &#91;\n      \t\tboundary_host.search_onprem.id\n\t\t]\n}\n\n\n# The target we use the host and add the port \nresource "boundary_target" "search_onprem" {\n  type         = "tcp"\n  name         = "search_9200"\n  description  = "9200 to search"\n  scope_id     = boundary_scope.onprem.id\n  default_port = "9200"\n  worker_filter = "\\"onprem\\" in \\"/tags/type\\""    &lt;--- REMEBER THIS TAG WE USE IN THE WORKER\n  host_source_ids = &#91;\n    boundary_host_set.search_onprem.id\n  ]\n}</code></pre>\n\n\n\n<p>so you can add more hosts and add them with IP ore DNS, Then you can assign targets to the hosts.<br>If you have workers running in some other location like AWS then you can simply deploy the worker and change the tag so it matches.</p>\n\n\n\n<p></p>\n\n\n\n<p></p>\n\n\n\n<p></p>\n', 'protected': False}</p>

            </div>
        </div>
    </section>


    <!-- Page Footer -->
    <footer class="page-footer">
        <div class="container">
            <div class="row align-items-center">
                <div class="col-sm-6">
                    <p>Copyright <script>document.write(new Date().getFullYear())</script> &copy; <a href="http://hacking.robots.beer" target="_blank">Mattias Hemmingsson / h.r.b AB </a></p>
                </div>
                <div class="col-sm-6">
                    <div class="socials">
                        <a class="social-item" href="javascript:void(0)"><i class="ti-github"></i></a>
                    </div>
                </div>
            </div>
        </div>
    </footer> 
    <!-- End of page footer -->
	
	<!-- core  -->
    <script src="/assets/vendors/jquery/jquery-3.4.1.js"></script>
    <script src="/assets/vendors/bootstrap/bootstrap.bundle.js"></script>
    <!-- bootstrap 3 affix -->
	<script src="/assets/vendors/bootstrap/bootstrap.affix.js"></script>

    <!-- steller js -->
    <script src="/assets/js/steller.js"></script>

</body>
</html>